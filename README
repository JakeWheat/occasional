A system for running concurrent and distributed processes

Examples TODO

running lots of tasks in parallel, three versions:
simplest possible in python
simplest possible which wraps an exe
'enterprise grade' with logging, monitoring

-> better error handling, online monitoring, easy logs, nicer ux, and
   distributed is why you may prefer this system to gnu parallel

running "server" exes, native and non native
  restarting when exit
  logging exit reasons
  providing monitoring and stuff

test framework

maybe a simple build system demo?
  -> run a lot of tasks
  some tasks are dependent on other tasks completion
  you want to use a specific amount of concurrency for heavy tasks
    (or even do categorization x cpu heavy tasks and y io heavy tasks)
  to demo using the system a bit more intensively, not as a non toy
  build system
  

Theory

A concurrency/distributed framework demo based on some ideas from
Erlang, built in Python, uses Linux processes (and not posix threads
or a green threads system). The most critical aspect of the design is
the reliable detection of spawned process exit with the reason why.

* you spawn a new process using a function to run without extra boilerplate
* you get an inbox with that process
* the system uses simple message passing with native values
* system processes are Linux processes
* you can reliably detect when and why a process exits on the local
  machine, whatever the reason
* you can as reliably as possible detect the same for remote processes
* there's a ports system like Erlang to run non native processes
* it's designed to build crash only systems, sigkill is routinely used
  on user processes

It is a usable system in its own right, it's also designed to be a
demo of one way to use Linux processes and sockets to create a system
like this, that could be ported to other programming languages.


